{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only using sensors data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config env and callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV CONF\n",
    "import carla \n",
    "# client = carla.Client(\"localhost\", 2000)\n",
    "# world = client.load_world('Town01')\n",
    "import gymnasium as gym\n",
    "from carla_env import CarEnv\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "class CARLA_G(gym.Env):\n",
    "    def __init__(self, ):\n",
    "        super(CARLA_G, self).__init__()\n",
    "        self.env = CarEnv()\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape = (2, ), dtype=np.float32)\n",
    "        self.observation_space = gym.spaces.Box(low = -np.inf, high = np.inf, shape=(16, ), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        [new_image, new_state], reward, done, info = self.env.step(action)\n",
    "        return new_state.astype(np.float32), reward, done, False, {}\n",
    "    \n",
    "    def reset(self, seed = None, options = {}):\n",
    "        image, state = self.env.reset()\n",
    "        return state.astype(np.float32), {}\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class MyCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(MyCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Check if there are completed episodes\n",
    "        if len(self.model.ep_info_buffer) > 0:\n",
    "            info = self.model.ep_info_buffer[-1]\n",
    "            self.episode_rewards.append(info['r'])\n",
    "            self.episode_lengths.append(info['l'])\n",
    "\n",
    "            # Here we log the episodic rewards and lengths to TensorBoard\n",
    "            self.logger.record('episode_reward', np.mean(self.episode_rewards[-100:]))\n",
    "            self.logger.record('episode_length', np.mean(self.episode_lengths[-100:]))\n",
    "            self.logger.dump(step=self.num_timesteps)\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "env = CARLA_G()\n",
    "town_name = 'Town01'\n",
    "env.env.town_name = town_name\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with MlpPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC, PPO, DDPG\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import os\n",
    "from stable_baselines3.common.logger import configure\n",
    "log_dir = \"./logs_sensor\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "#model conf\n",
    "#---new model\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1,buffer_size=1000000,tensorboard_log=log_dir)\n",
    "\n",
    "#---load model\n",
    "# if you countinue learning from saved model, uncomment this lines:\n",
    "# model = SAC.load(\"model name\", print_system_info=True)\n",
    "# model2 = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "# model.env = model2.env\n",
    "# model.load_replay_buffer(\"./buffer_SAC_model_sesnor.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "# Pass a TensorBoard logger to the model\n",
    "new_logger = configure(log_dir, [\"stdout\", \"tensorboard\"])\n",
    "\n",
    "\n",
    "# Instantiate the callback\n",
    "my_callback = MyCallback()\n",
    "model.set_logger(new_logger)\n",
    "\n",
    "for i in range(10000000):\n",
    "    try:\n",
    "        name = \"SAC_model_sesnor_run_\"+str(i+1)\n",
    "        print(name)\n",
    "        model.learn(total_timesteps=5000, log_interval=4,callback = my_callback)\n",
    "        model.save(name)\n",
    "        #saving realy buffer for next learning process\n",
    "        model.save_replay_buffer(\"buffer_SAC_model_sesnor.pkl\")\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using camera data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config env and callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV CONF\n",
    "import carla \n",
    "# client = carla.Client(\"localhost\", 2000)\n",
    "# world = client.load_world('Town01')\n",
    "import gymnasium as gym\n",
    "from carla_env import CarEnv\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class CARLA_G_camera(gym.Env):\n",
    "    def __init__(self, ):\n",
    "        super(CARLA_G_camera, self).__init__()\n",
    "        self.env = CarEnv()\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape = (2, ), dtype=np.float32)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1,shape=(3,60,160), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        [new_image, new_state], reward, done, info = self.env.step(action)\n",
    "        first_ch_new_image = np.moveaxis(new_image,-1,0)/255\n",
    "        return (first_ch_new_image.astype(np.float32)), reward, done, False, {}\n",
    "    \n",
    "    def reset(self, seed = None, options = {}):\n",
    "        image, state = self.env.reset()\n",
    "        first_ch_image = np.moveaxis(image,-1,0)/255\n",
    "\n",
    "        return first_ch_image.astype(np.float32), {}\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class MyCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(MyCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Check if there are completed episodes\n",
    "        if len(self.model.ep_info_buffer) > 0:\n",
    "            info = self.model.ep_info_buffer[-1]\n",
    "            self.episode_rewards.append(info['r'])\n",
    "            self.episode_lengths.append(info['l'])\n",
    "\n",
    "            # Here we log the episodic rewards and lengths to TensorBoard\n",
    "            self.logger.record('episode_reward', np.mean(self.episode_rewards[-100:]))\n",
    "            self.logger.record('episode_length', np.mean(self.episode_lengths[-100:]))\n",
    "            self.logger.dump(step=self.num_timesteps)\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "env = CARLA_G_camera()\n",
    "town_name = 'Town01'\n",
    "env.env.town_name = town_name\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CustomSACPolicy policy_kwargs based on resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import DQN, SAC\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "# from stable_baselines3.dqn.policies import DQNPolicy\n",
    "from stable_baselines3.sac.policies import Actor, CnnPolicy, MlpPolicy, MultiInputPolicy, SACPolicy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet_18(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        \n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        \n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "            \n",
    "        return nn.Sequential(\n",
    "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
    "            Block(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    \n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "class CustomResNetFeaturesExtractor(BaseFeaturesExtractor):\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 100):\n",
    "        super(CustomResNetFeaturesExtractor, self).__init__(observation_space, features_dim)\n",
    "        extractors = {}\n",
    "        total_concat_size = 0\n",
    "        # We need to know size of the output of this extractor,\n",
    "        # so go over all the spaces and compute output feature sizes\n",
    "        for  subspace in observation_space.spaces.items():\n",
    "                extractors = nn.Sequential(ResNet_18(3, 100)).to('cuda:0')\n",
    "                total_concat_size += 100 #subspace.shape[1] // 4 * subspace.shape[2] // 4\n",
    "                \n",
    "\n",
    "        self.extractors = nn.ModuleDict(extractors).to('cuda:0')\n",
    "        print(self.extractors)\n",
    "        self._features_dim = 32 #total_concat_size\n",
    "        # print(self._features_dim)\n",
    "        self.fc1 = nn.Linear(100,32)\n",
    "        self.fc2 = nn.Linear(32,32)\n",
    "        # self.fc3 = nn.Linear(256,features_dim)#done\n",
    "\n",
    "    def forward(self, observations) -> torch.Tensor:\n",
    "        encoded_tensor_list = []\n",
    "\n",
    "        for key, extractor in self.extractors.items():\n",
    "            encoded_tensor_list.append(extractor(observations))\n",
    "\n",
    "        x = torch.cat(encoded_tensor_list, dim=1).to('cuda:0')\n",
    "        # print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.fc3(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "class CustomSACPolicy(SACPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "obs_space = env.observation_space\n",
    "\n",
    "# Define the policy_kwargs to use the features extractor\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomResNetFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=100),\n",
    "    net_arch=[]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with CustomSACPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC, PPO, DDPG\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import os\n",
    "from stable_baselines3.common.logger import configure\n",
    "log_dir = \"./logs_camera\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "#model conf\n",
    "#---new model\n",
    "model = SAC(\n",
    "    policy=CustomSACPolicy,\n",
    "    env=env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=1,\n",
    "    buffer_size=20000 ,\n",
    "    learning_rate=3e-4,\n",
    "    batch_size=128*4,\n",
    "    gamma=0.99,\n",
    "    train_freq=4,\n",
    "    gradient_steps=1,\n",
    "    target_update_interval=1000,\n",
    ")\n",
    "\n",
    "#---load model\n",
    "# if you countinue learning from saved model, uncomment this lines:\n",
    "# model = SAC.load(\"model name\", print_system_info=True)\n",
    "# model2 = SAC(policy=CustomSACPolicy,env=env,policy_kwargs=policy_kwargs,verbose=1)\n",
    "# model.env = model2.env\n",
    "# model.load_replay_buffer(\"./buffer_SAC_model_camera.pkl\")\n",
    "\n",
    "\n",
    "# Pass a TensorBoard logger to the model\n",
    "new_logger = configure(log_dir, [\"stdout\", \"tensorboard\"])\n",
    "\n",
    "\n",
    "# Instantiate the callback\n",
    "my_callback = MyCallback()\n",
    "model.set_logger(new_logger)\n",
    "\n",
    "for i in range(10000000):\n",
    "    try:\n",
    "        name = \"SAC_model_camera_run_\"+str(i+1)\n",
    "        print(name)\n",
    "        model.learn(total_timesteps=5000, log_interval=4,callback = my_callback)\n",
    "        model.save(name)\n",
    "        #saving realy buffer for next learning process\n",
    "        model.save_replay_buffer(\"buffer_SAC_model_camera.pkl\")\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sensors and camera data (fusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config env and callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV CONF\n",
    "import carla \n",
    "# client = carla.Client(\"localhost\", 2000)\n",
    "# world = client.load_world('Town01')\n",
    "import gymnasium as gym\n",
    "from carla_env import CarEnv\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "class CARLA_G_fusion(gym.Env):\n",
    "    def __init__(self, ):\n",
    "        super(CARLA_G_fusion, self).__init__()\n",
    "        self.env = CarEnv()\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape = (2, ), dtype=np.float32)\n",
    "        # self.observation_space = gym.spaces.Box(low = -np.inf, high = np.inf, shape=(16, ), dtype=np.float32)\n",
    "        self.observation_space = gym.spaces.Dict({\"image\": gym.spaces.Box(low=0, high=1,shape=(3,60,160), dtype=np.float32), \"tracking\": gym.spaces.Box(low = -np.inf, high = np.inf, shape=(16, ), dtype=np.float32)})\n",
    "\n",
    "    def step(self, action):\n",
    "        [new_image, new_state], reward, done, info = self.env.step(action)\n",
    "        first_ch_new_image = np.moveaxis(new_image,-1,0)/255\n",
    "        return {\"image\":first_ch_new_image.astype(np.float32), \"tracking\":new_state.astype(np.float32)}, reward, done, False, {}\n",
    "    \n",
    "    def reset(self, seed = None, options = {}):\n",
    "        image, state = self.env.reset()\n",
    "        first_ch_image = np.moveaxis(image,-1,0)/255\n",
    "\n",
    "        return {\"image\":first_ch_image.astype(np.float32),\"tracking\":state.astype(np.float32)}, {}\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class MyCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(MyCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Check if there are completed episodes\n",
    "        if len(self.model.ep_info_buffer) > 0:\n",
    "            info = self.model.ep_info_buffer[-1]\n",
    "            self.episode_rewards.append(info['r'])\n",
    "            self.episode_lengths.append(info['l'])\n",
    "\n",
    "            # Here we log the episodic rewards and lengths to TensorBoard\n",
    "            self.logger.record('episode_reward', np.mean(self.episode_rewards[-100:]))\n",
    "            self.logger.record('episode_length', np.mean(self.episode_lengths[-100:]))\n",
    "            self.logger.dump(step=self.num_timesteps)\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "env = CARLA_G_fusion()\n",
    "town_name = 'Town01'\n",
    "env.env.town_name = town_name\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CustomSACPolicy policy_kwargs based on resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import DQN, SAC\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "# from stable_baselines3.dqn.policies import DQNPolicy\n",
    "from stable_baselines3.sac.policies import Actor, CnnPolicy, MlpPolicy, MultiInputPolicy, SACPolicy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet_18(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        \n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        \n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "            \n",
    "        return nn.Sequential(\n",
    "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
    "            Block(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    \n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "class CustomResNetFeaturesExtractor(BaseFeaturesExtractor):\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 116):\n",
    "        super(CustomResNetFeaturesExtractor, self).__init__(observation_space, features_dim)\n",
    "        extractors = {}\n",
    "        total_concat_size = 0\n",
    "\n",
    "        for key, subspace in observation_space.spaces.items():\n",
    "            if key == \"image\":\n",
    "                extractors[key] = nn.Sequential(ResNet_18(3, 100)).to('cuda:0')\n",
    "                total_concat_size += 100 #subspace.shape[1] // 4 * subspace.shape[2] // 4\n",
    "                print( subspace.shape[2] )\n",
    "            elif key == \"tracking\":\n",
    "                extractors[key] = nn.Linear(subspace.shape[0], 16).to('cuda:0')\n",
    "                total_concat_size += 16\n",
    "        self.extractors = nn.ModuleDict(extractors).to('cuda:0')\n",
    "        print(self.extractors)\n",
    "        self._features_dim = 32 #total_concat_size\n",
    "        # print(self._features_dim)\n",
    "        self.fc1 = nn.Linear(116,32)\n",
    "        self.fc2 = nn.Linear(32,32)\n",
    "        # self.fc3 = nn.Linear(256,features_dim)#done\n",
    "\n",
    "    def forward(self, observations) -> torch.Tensor:\n",
    "        encoded_tensor_list = []\n",
    "\n",
    "        for key, extractor in self.extractors.items():\n",
    "            encoded_tensor_list.append(extractor(observations[key]))\n",
    "\n",
    "        x = torch.cat(encoded_tensor_list, dim=1).to('cuda:0')\n",
    "        # print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        # # print(x.shape)\n",
    "        # x = self.fc3(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "class CustomSACPolicy(SACPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "obs_space = env.observation_space\n",
    "\n",
    "# Define the policy_kwargs to use the features extractor\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomResNetFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=116),\n",
    "    net_arch=[]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with CustomSACPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC, PPO, DDPG\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import os\n",
    "from stable_baselines3.common.logger import configure\n",
    "log_dir = \"./logs_fusion\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "#model conf\n",
    "#---new model\n",
    "model = SAC(\n",
    "    policy=CustomSACPolicy,\n",
    "    env=env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=1,\n",
    "    buffer_size=20000 ,\n",
    "    learning_rate=3e-4,\n",
    "    batch_size=128*4,\n",
    "    gamma=0.99,\n",
    "    train_freq=4,\n",
    "    gradient_steps=1,\n",
    "    target_update_interval=1000,\n",
    ")\n",
    "\n",
    "#---load model\n",
    "# if you countinue learning from saved model, uncomment this lines:\n",
    "# model = SAC.load(\"model name\", print_system_info=True)\n",
    "# model2 = SAC(policy=CustomSACPolicy,env=env,policy_kwargs=policy_kwargs,verbose=1)\n",
    "# model.env = model2.env\n",
    "# model.load_replay_buffer(\"./buffer_SAC_model_fusion.pkl\")\n",
    "\n",
    "\n",
    "# Pass a TensorBoard logger to the model\n",
    "new_logger = configure(log_dir, [\"stdout\", \"tensorboard\"])\n",
    "\n",
    "\n",
    "# Instantiate the callback\n",
    "my_callback = MyCallback()\n",
    "model.set_logger(new_logger)\n",
    "\n",
    "for i in range(10000000):\n",
    "    try:\n",
    "        name = \"SAC_model_fusion_run_\"+str(i+1)\n",
    "        print(name)\n",
    "        model.learn(total_timesteps=5000, log_interval=4,callback = my_callback)\n",
    "        model.save(name)\n",
    "        #saving realy buffer for next learning process\n",
    "        model.save_replay_buffer(\"buffer_SAC_model_fusion.pkl\")\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        time.sleep(0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
